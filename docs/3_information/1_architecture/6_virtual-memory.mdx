---
title: 6. 仮想記憶
---

[メモリ管理](/docs/information/os/memory) も参照

## 仮想記憶の概要
:::tip[仮想記憶]
各プロセスに物理メモリとは独立にアドレス空間を提供する技術。また，これによりメモリ (主記憶) データを補助記憶 (ストレージ) に配置・管理することができる。
システム (HW + SW) が制御する，ユーザ透過なものである。
これにより，プログラムはメモリよりも大きなデータを扱えるようになる。
:::
- メインメモリの下にキャッシュ階層を補助記憶に設ける，という捉え方もできる
- スワップ領域 (ページング領域) : 仮想記憶のうち，補助記憶を使う領域

> 仮想記憶の利点
> - プログラムに物理的に存在するメモリより大きいメモリを見せられる
> - 同時に動く複数のプロセスに対して，同じ物理メモリを共有できる
> - プロセスごとにアドレス空間を分離・保護できる

プログラムやユーザは，メモリ空間を全て使うつもりでメモリを指定してアクセスする。ただ，実際に物理メモリが存在するとは限らない。
そこで，仮想記憶を用いることでそこらへんをうまく隠蔽する。

:::tip[仮想記憶の機能]
大きく分けて，以下の機能を持つ。
- プロセス同士のアドレス空間を分離して保護する (MMU (HW) がアクセスを検知し，OS が制御する。[メモリ管理ユニット (MMU)](/docs/information/os/memory#メモリ管理ユニット-mmu) も参照)
- 論理アドレス (仮想アドレス) を物理アドレスに変換する (アドレス変換。MMU (HW) が行う)
- よく使うデータをメインメモリに置き，それ以外のデータは補助記憶に置く (ページング。OS が行う。[メモリ割り当て](/docs/information/os/memory#メモリ割り当て) を参照)
    - ページ置換アルゴリズム : ページ (データブロック) をメモリから補助記憶に移動する際のアルゴリズム ([ページ置換アルゴリズム](/docs/information/os/memory#ページ置換アルゴリズム) を参照)
:::

---
## アドレス変換
:::note[論理アドレスと物理アドレス]
**論理 (仮想) アドレス** : 各プロセスが持つアドレス空間のことで，プログラム上ではそのアドレスにアクセスすることでデータを扱うことができる。
異なるプロセス間で同じ論理アドレスが存在することもある。

**物理アドレス** : 実際のメモリ上のアドレスで，ハードウェアが直接アクセスするアドレス。
:::
上記を実装することで，プロセス同士のアドレス空間の分離と保護を実現する。 (つまり，論理アドレス空間をプロセスごとに作る)  
後は，うまく論理アドレスと物理アドレス (+ 補助記憶) の対応を取れればよい。$\to$ アドレス変換を行う。

:::tip[アドレス変換]
アドレス変換は，論理アドレスと物理アドレスの対応をとること。以下のような技術を使う。
- MMU (メモリ管理ユニット) : CPU と メモリの間に位置するハードウェアで，全てのメモリアクセスを制御する
- ページテーブル : 論理ページ番号と物理ページ番号の対応表。メモリ内に構成される
- TLB (Translation Lookaside Buffer) : ページテーブルのキャッシュ。MMU 内に構成される
:::


論理アドレスで，下位 $A$ bit 以外が共通の $2^A$ 個のアドレスからなる領域のことを **ページ** と呼ぶ。
- ページサイズは $2^A$ byte (典型例は，$A = 12$，ページサイズ : 4KB)
- 論理アドレスは，[論理ページ番号, ページ内オフセット ($A$ bit)] の形で表現
- 論理アドレスのサイズは OS によって決定される。例えば，32, 36 bit など

そこで，論理アドレスと物理アドレスの対応はこのようにすれば取れる。
:::tip[論理アドレスと物理アドレスの対応]
ページ内オフセットを共通として，論理ページ番号と物理ページ番号をページテーブルで対応させる。
ただし，論理ページ番号と物理ページ番号のサイズは異なることがある。
- 論理アドレス : [論理ページ番号, ページ内オフセット ($A$ bit)]
- 物理アドレス : [物理ページ番号, ページ内オフセット ($A$ bit)]
:::

### ページテーブル
:::tip[ページテーブル]
ページテーブルは，論理ページ番号と物理ページ番号の対応を保持する。
- **メモリ内に構成される** (ページテーブルレジスタに，ページテーブルの先頭アドレスが格納される)
- **プロセスごとに構成される**
- キャッシュと比べて，ミスによる遅延が大きい (補助記憶へのアクセスが必要になるため)
- OS が作成し，MMU が制御する ([メモリ管理ユニット (MMU)](/docs/information/os/memory#メモリ管理ユニット-mmu) も参照)
:::
具体的には，以下のようにして対応関係を持つ。[キャッシュの作り方](/docs/information/architecture/cache#キャッシュの作り方) とも比較。

なお，論理アドレスを $v$ bit (例えば 32 bit)，物理アドレスを $b$ bit (例えば 30 bit) とする。
> 1. 論理アドレスを **[論理ページ番号 ($v - A$ bit), ページ内オフセット ($A$ bit)]** の形に分割する
> 2. 仮想ページ番号をインデックスとして，ページテーブルを参照する。各エントリは，**[有効ビット, 物理ページ番号 ($b - A$ bit), アクセス権など]** となっている
> 3. 有効ビットが 1 であれば，[物理ページ番号, ページ内オフセット ($A$ bit)] の形で物理アドレスを生成する
>     - 有効ビットが 0 の場合は，**ページフォルト** が発生する

全ての論理ページ番号に対してエントリを用意するため，ページテーブルは大きい。
- 例 : 論理アドレス 32 bit, ページサイズ 4KB ($A = 12$), ページテーブルのエントリサイズ 4B (各エントリのサイズ) の場合，
ページテーブルのサイズは $2^{(32 - 12)} \times 4$ B = 4 MB

**ページフォルト** : 論理アドレスに対応する物理ページが存在しない場合に発生する $\to$ 例外を発生させ，OS に制御を移す。  
具体的な OS による処理は，[メモリ割り当ての動作例](/docs/information/os/memory#メモリ割り当ての動作例) を参照。

### ページテーブルの減量
ページテーブルは大きいので，以下のような減量方法が存在する
- プロセスが新しい仮想ページを要求するたびに，ページテーブルのエントリを追加する
- ハッシュを用いて，エントリ数と物理ページ数を同じにする (キャッシュの時のように)
- 多段化する (よく使われる)。上位の論理アドレス (例えば 8 bit ずつ) から順にページテーブルの参照を繰り返すようにすることで，
使用されていないビット部分の下位ページテーブルを作らなくてもよくなる

### TLB (Translation Lookaside Buffer)
:::tip[TLB]
ページテーブルはメモリに存在するため，メモリのアクセスが 2 度必要になってしまう (論理アドレス $\to$ 物理アドレス $\to$ データ)。
そこで，ページテーブルのキャッシュを MMU 内にある SRAM などに保存しておく。(全プロセスで共有)
- キャッシュと同様に，論理アドレスを [タグ, インデックス, ページ内オフセット] の形に分割して，インデックスを使いエントリを見てタグを比較する
:::
画像は [MMU（メモリマネージメントユニット）](https://www.aps-web.jp/academy/ca/228/) より引用
<img  src="https://www.aps-web.jp/wp-data/wp-content/uploads/2019/06/acd-ca-12-fig01.png" alt="TLB のイメージ図" style={{ width: '50%' }} />
つまり，論理アドレスからデータを取得するまでは以下のような流れがありうる。
- 論理アドレス $\to$ TLB (ヒット) $\to$ 物理アドレス $\to$ (キャッシュ，必要ならメモリ) $\to$ データ
- 論理アドレス $\to$ TLB (ミス) $\to$ ページテーブル (ヒット) $\to$ 物理アドレス $\to$ (キャッシュ，必要ならメモリ) $\to$ データ
- 論理アドレス $\to$ TLB (ミス) $\to$ ページテーブル (ミス) $\to$ ページフォルト (OS に制御を移す) $\to$ 補助記憶 (スワップ領域) 
$\to$ TLB や ページテーブルの更新 (ここまで OS の指示で) $\to$ TLB (ヒット) $\to$ 物理アドレス $\to$ (キャッシュ，必要ならメモリ) $\to$ データ

仮想記憶とキャッシュの連携について
- 論理アドレスキャッシュ : キャッシュの連想検索を物理アドレスではなく論理アドレスのタグ・インデックスで行う
- 物理アドレスキャッシュ : キャッシュの連想検索を物理アドレスのタグ・インデックスで行う (上記の流れの例。一般的)
- インデックスは論理アドレス，タグは物理アドレスで行う (キャッシュを論理アドレスで探すと同時に，TLB を参照して物理アドレスを取得する)

---
## I/Oシステムの仕組み
(仮想記憶とは全然関係ない。)
:::note[I/Oシステム]
I/O (入出力) とは，CPU やメモリが，それ以外の外部デバイスとデータをやり取りする仕組み全般を指す。
- **入出力装置** : メモリ以外とのやりとりを行う装置。ユーザ，補助記憶，ネットワークなど
- 物理的には，CPU，メモリ，I/Oデバイスはシステムバス (アドレスバス、データバス、コントロールバスなど) に接続される
:::
外部デバイスには，ファームウェアなどデバイスを動かすためのコントローラやレジスタがあり，そことの連携が不可欠。

#### CPU と外部デバイスのレジスタの読み書き
- メモリマップド I/O (MMIO) : メモリアドレスの特定領域を I/O デバイスに割り当てる。CPU から見るとメモリアクセスするのと同じ命令でデバイスのレジスタにアクセスできる
- ポートマップド I/O (PMIO) : 専用のメモリアドレス空間を設ける。`IN` や `OUT` など特別な命令を使って，特定のポートにアクセスすることでデバイスのレジスタにアクセスする

#### データの転送方式
- PIO (Programmed I/O) : CPU が命令を実行し，データを順々に転送する方式。大量のデータ転送には向かない
- DMA (Direct Memory Access) : DMA コントローラ (DMA controller) と呼ばれる専用ハードウェアがデバイスとメモリ間のデータ転送を直接実行する方式
    - CPU は DMA に転送元・転送先アドレス・データサイズを指定すれば DMA が自動的に転送を行う

#### 非同期処理のためのメカニズム
- ポーリング : CPU が定期的に外部デバイスの状態をビジーループで確認する仕組み。 確認できたら，次の処理を行う
- 割り込み : 外部デバイスが何かしらの処理を終えたときに CPU に通知する仕組み。CPU は割り込みを受けて，割り込みハンドラと呼ばれる専用の処理を行う

#### OS による I/O の抽象化
OS によって，I/O を抽象化し，様々なデバイスを統一的な API で扱えるようにする。
- デバイスドライバ : OS の一部で，デバイスを直接制御し，デバイスの複雑な使用を隠蔽するソフトウェア。

#### I/O の同期と非同期
- 同期I/O (Synchronous I/O) : プログラムが I/O 処理の API を叩いた際，その処理が完了するまでプロセスを待機状態にする方式
- 非同期I/O (Asynchronous I/O) : プログラムが I/O 処理の API を叩いた際，OS が要求を受け付けたら別の処理を続行し，I/O 処理が完了したらプロセスに通知する方式