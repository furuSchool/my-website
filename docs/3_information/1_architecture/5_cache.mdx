---
title: 5. キャッシュ
---

## 階層記憶
:::warning[階層記憶]
プログラマは大きいメモリが欲しい $\leftrightarrow$ プロセッサは高速なメモリが欲しい。

この要望を両立する方法として，**階層化** がある。メモリアクセスの **局所性** を利用して，高速度と大容量を両立する。
:::
- 一般には，大きいメモリ = 低速・高価

### メモリアクセスの局所性
:::note[メモリアクセスの局所性]
メモリアクセスには偏りがある。
1. **時間的局所性** : あるデータ (アドレス) がアクセスされた後，近い将来に再度アクセスされる可能性が高い
2. **空間的局所性** : あるデータ (アドレス) がアクセスされた後，近いアドレスのデータがアクセスされる可能性が高い
:::
- 例 : 配列を走査する場合，配列の要素は連続してアクセスされるため，空間的局所性が高い
- 例 : for 文の中で同じ変数を何度も使う場合，時間的局所性が高い

つまり局所性を利用して適宜入れ替えながら，よく使われるデータを高速・小容量の記憶装置に，そうでないデータを低速・大容量の記憶装置に配置すれば良い !

### 記憶階層の設計
:::tip[記憶階層の設計]
記憶階層は以下のように設計することが多い。上から (**高速・小容量・高価**) から順に説明する
1. **レジスタ** : CPU 内の高速な記憶装置。各 CPU コアに存在。フリップフロップを使用する。
    - 数十 ~ 数百 byte。レイテンシ : 1 (サイクル / CLK) 未満，0.1 ns 程度
2. **キャッシュ** : CPU とメインメモリの間にある高速な記憶装置。SRAM などを使用する。この内部でも階層化される
    - L1 キャッシュ : 数十 KB。各 CPU コアに存在。レイテンシ : 数 (サイクル / CLK)，~ 1 ns 程度
    - L2 キャッシュ : 数 MB。各コアに専用，または少数コアで共有。レイテンシ : 数十 (サイクル / CLK)，数 ns 程度
    - L3 キャッシュ : 数十 MB。全コアで共有。レイテンシ : 数十 (サイクル / CLK)，~10 ns 程度
3. **メインメモリ (主記憶)** : メモリと呼ばれる記憶装置。DRAM などを使用する。これ以降はオフチップ ( = CPU から遠い) である
    - 4, 8, 16 GB など。レイテンシ : 数十 ~ 数百 (サイクル / CLK)，数十 ns 程度
4. ディスクキャッシュ : OS が管理して，メインメモリの一部を利用する。頻繁にアクセスされるファイルやデータをキャッシュする
5. **補助記憶装置 (セカンダリストレージ)** : ハードディスクや SSD ( NAND フラッシュメモリを利用) など電源を切ってもデータが保持される記憶装置。
    - 256, 512 GB ~ 1 TB など。レイテンシ : 数万 ~ 数百万 (サイクル / CLK)，~ 100 μs 程度
:::
<img src="http://img.allabout.co.jp/gm/article/52686/kaisou.gif" alt="記憶階層" style={{ width: '30%' }} />

画像は [メモリ階層とネットワークの基礎](https://www.ei.fukui-nct.ac.jp/2010/11/08/post-1053/) より引用
- クロック周波数はだいたい数 GHz (0.1~1 ns)
- PC などは複数の CPU コアを持ち，互いに協働して動作することが多い
- メインメモリまでのアクセス最適化はハードウェア (CPU) で，それより長い遅延のアクセス最適化はソフトウェア (OS) で行うことが多い
- トレードオフの観点 : 揮発/不揮発，集積度，容量単価，アクセスレイテンシ，アクセススループット，信頼性・寿命
- 実際の装置 : SRAM，DRAM，フラッシュメモリ，磁気ディスク，光ディスク，磁気テープ，コアメモリ，パンチカード，水銀遅延線，…

また，記憶階層の制御の観点では二つの方式がある。
1. 階層間の移動などの命令を明示的に作り，ソフトウェアで細かく制御
    - ここは，[メモリ管理](/docs/information/os/memory) も参照
2. プログラムからハードウェアが最適化を行い自動的に制御 (つまり，ソフトウェアから記憶階層は見えない)

---
## キャッシュ
:::tip[キャッシュ]
自動的・効率的に記憶階層を活用する技術。上位階層に下位階層の "サブセット" を持たせるイメージ。
- **暗黙的制御** : ハードウェアやミドルウェア (OS など) が自動的に制御
- **キャッシュヒット率** が重要 : キャッシュに目的のデータがあるかどうか
:::

### キャッシュの基本
:::tip[キャッシュの基本]
CPU (プロセッサ) に近い方から，L1, L2, L3 キャッシュと呼ばれる。上位階層から順にデータを検索し，見つかれば「ヒット」，なければ「ミス」で下位階層へ行く。
- ヒット時 : ヒットの判定 + 読み出し
- ミス時 : ミスの判定 + 下位階層からのデータ読み出し + 上位階層への書き込み (上位キャッシュに保存する)
:::

**キャッシュブロック** : キャッシュの格納はブロック単位で行う。つまり，32, 64, 128 B 程度のデータを一気に下位階層から持ってくる。空間的局所性を利用した方法である。

**連想検索** : あるメモリアドレスに対応するデータがどこにあるか，メモリアドレスのみからすぐに判定できるようにすること。
キャッシュの場合は，メモリアドレスの下位ビットを切り出してハッシュとして利用する。

**ライトスルー方式** : キャッシュのデータが変更される際，同時に下位階層のデータも更新する方式。  
**ライトバック方式** : キャッシュのデータが変更されるても下位階層のデータは更新せず、キャッシュから追い出される際にまとめて更新する方式。
これにより、書き込みの回数を減らせるが，処理が複雑になる。

### キャッシュの作り方
:::tip[キャッシュの作り方]
キャッシュは，主に以下の 3 つの方法で作られる。
1. **ダイレクト・マッピング** : 各メモリアドレスは，キャッシュの特定の位置にのみ格納される。単純で検索が高速だが，衝突が起きやすい。
2. **セット・アソシアティブ** : 各メモリアドレスは，キャッシュの複数のブロックのどこかに格納される。
3. **フル・アソシアティブ** : 各メモリアドレスは，キャッシュのどの位置にも格納されうる。最も柔軟だが，検索が遅くなる。
:::

### ダイレクト・マッピング
:::note[ダイレクト・マッピング]
メモリアドレスの一部のビット列をキャッシュのインデックスとして使用し，その位置にのみデータを格納する方法。
格納する際，キャッシュはブロックごと (例えば 64 B) にデータを格納する。
:::

ブロックサイズ $2^{b}$ Byte，キャッシュのエントリサイズ (ブロック数) $2^{e}$ ビットのキャッシュがあるとする。  
(例えば，$b = 6, e = 10$ だと，ブロックサイズは 64 B，キャッシュ内のブロック数は 1024 個，この時，各ブロックには 32 bit × 16 個のデータが格納される)
1. メモリアドレスを **[タグ, インデックス, オフセット]** の 3 つの部分に分割する
    - タグ : どのメモリアドレスに対応するかを示す。$32 - e - b$ bit (メモリアドレスが 32 bit の場合)
        - **タグのみが異なるメモリアドレスは衝突する**
    - インデックス : どのブロックにあるか区別する。$e$ bit
    - オフセット : ブロック内でどこにあるかを区別する。$b$ bit
2. キャッシュに格納する。各アドレスのデータブロックは，**インデックス行に [有効ビット, タグ, データ]** の形で格納される 
    - キャッシュ全体の大きさは，エントリサイズ × (有効ビット + タグ + データブロック) となる。 
        - $2^e \times (1 + (32 - e - b) + 2^b \times 8)$ bit 
            - $2^e \times (1 + (32 - e - b) + 2^{b-2} \times 32)$ bit とも。この場合は 32 bit のデータを $2^{b-2}$ 個格納するイメージ
        - 例 : エントリ数 1024，ブロックサイズ 64 B の場合，タグ 16 bit, インデックス 10 bit, オフセット 6 bit であり，
        $1024 × (1 + 16 + 64 × 8)$ bit $= 66$ KB
    - 有効ビット : データが格納されているかどうか。0 or 1
    - タグ : ここに格納されうるデータのうち，どのメモリアドレスに対応するかを示す
    
#### キャッシュの検索
1. メモリアドレスを [タグ, インデックス, オフセット] に分割し，キャッシュのインデックス行を調べる
2. キャッシュのインデックス行が有効ビット 1 かどうか，タグが一致するかどうかを確認する
3. タグが一致すれば，データブロック (データアレイ) のオフセット位置を参照してデータを取得する (ヒット)

### セット・アソシアティブ
:::note[セット・アソシアティブ]
各メモリアドレスは，キャッシュの複数のブロックのどこかに格納される。格納場所が $n$ 通りの時，$n$ ウェイと呼ばれる。$n$ を連想度ともいう。
キャッシュ利用効率の向上が期待できるが，ウェイ数分アクセスが遅くなる。
:::
この場合，以下がダイレクト・マッピングと異なる特徴となる。フル・アソシアティブはセット・アソシアティブで $n = 2^{e}$ の場合と同じ。
- ブロックを複数まとめた **セット** を作る。セット内にブロックが $n$ 個ある
- インデックスはセットの番号を示し，$e - \log_2 n$ bit となる
- 検索時はセット内の全てのブロックを調べる必要がある
- セットがいっぱいの時にさらにデータを格納する場合，**置換アルゴリズム** (LRU など) を使用して，どのブロックを置き換えるか決定する
    - LRU (Least Recently Used) : 最も長い間使用されていないブロックを置き換える

### キャッシュミスの 3 C
:::tip[キャッシュミスの 3 C]
キャッシュミスには 3 つの種類がある。
1. 初期参照ミス (compulsory miss)：不可避。そのライン (データ) への最初のアクセス
2. 競合ミス (conflict miss) : 同じセットへのアクセスによって追い出されたラインへのアクセス。フル・アソシアティブで防げる
3. 容量性ミス (capacity miss) : キャッシュ容量がたりないために追い出されたラインへのアクセス
:::