---
title: 1. 情報理論の基礎
---

:::warning[目標]
情報理論は，情報伝達をいかに高効率・高信頼で行うかに関する理論。情報理論の問題設定とモデルを理解する！
:::

---
### 通信システムのモデル化
そもそも情報の伝達とは何なのか？
本質的には情報の受け手の世界の変化であるはずだが，これを情報理論で扱うことは難しい。
そこで，受け手の世界が限定され普遍性を持つ場合について考える。

**ある集合に対し，何らかの統計的知識に基づいて受け手が与えている確率分布の変化を，情報の伝達と捉える。**

:::tip[用語]
- 情報源：情報が発生する源。
- 通報：情報源から発する "もの"。英文や数字など様々。ディジタル通報とアナログ通報がある。情報源から発する記号を **情報源記号** といい，基本的にこれを扱う
- 符号：情報源記号に割り当てた各系列（符号語）の集合。(例) \{0, 1}, \{00, 01, 10, 11}
    - 符号アルファベット：符号語に用いられる記号の集合。(例の場合はともに \{0, 1})
    - アルファベットが $q$ 個の符号 $\to$ **$q$ 元符号** (例の場合はともに2元符号)
- 通信路：通報があて先に送られる時に通るもの。電線，光ファイバー，空間など。通報に雑音や歪みを付加し得る。入力・出力の形式によって，アナログ通信路とディジタル通信路がある
- 符号化：通報を通信路に入力できるように変換をすること。逆の操作は復号という
    - 復号誤り率：復号を誤る確率
    - **情報源符号化：情報源の統計的性質を利用して，通信効率の向上を図る符号化**
    - **通信路符号化：通信路の雑音や誤りに対処し，高信頼化を図る符号化**
:::
- 情報源記号は，情報源アルファベット (集合) の元であると考えれば良い

そこで，通信システムは以下のような流れで考えることが多い。
:::tip[通信システムのモデル]
1. 情報源から情報源記号の系列 (情報源系列) が発生
2. 情報源符号化と通信路符号化を行い，符号系列を得る
3. 通信路を通る (この前後に変調と復調を行ってアナログ通信路を用いることが多いが，情報理論では触れない)
4. 通信路復号と情報源復号を行う。この結果，推定された情報源系列を得る
5. あて先に推定された情報源系列が届く
:::
<img src="/img/information/system_model.jpg" alt="通信システムのモデル" style={{ width: '80%' }} />
画像は，[情報科学](https://kotobank.jp/word/%E6%83%85%E5%A0%B1%E7%A7%91%E5%AD%A6-4560) より引用

### 情報理論の分野
1. シャノン理論：情報の量的表示及び符号化の限界に関する理論
2. 符号理論：具体的な情報の符号化に関する理論。狭義では通信路符号化法のみを指す。ディジタルに関連することが多い
3. 信号理論：信号の解析や設計に関する理論。情報伝達の媒体である信号そのものが研究の対象になることもあり，情報の伝達が意識されないことも多い。
また，アナログに関連することが多い

---
## 問題設定
:::warning[目標]
1. 通信路使用の効率の向上を図る（送信する記号数の減少(ディジタル)，所要時間や使用周波数帯域の減少など(アナログ)）= **情報源符号化**
2. 信頼性の向上を図る（誤り率の減少(ディジタル)，雑音の減少(アナログ)）= **通信路符号化**
:::
一般に同時に考えるのが望ましいが，難しい場合が多いため，問題を分割して考える。

また，その他の問題設定として，以下のようなものがある
- 通信システムのモデルの多様化：双方向通信システムにおける通信路符号化（ARQ方式など），
多元接続形通信システム（$m$ 入力 $n$ 出力），放送型通信システム（$1$ 入力 $n$ 出力），多入力多出力通信システム（MIMO）
    - ネットワーク符号化などが用いられる
- 情報セキリュティのための符号化（暗号化）

---
## 情報源のモデル

:::tip[情報源のモデル]
離散 $M$ 元情報源（ディジタル）を考える。これは，定められた時点で，情報源アルファベットの元である情報源記号を一つずつ出力する
- 情報源アルファベット：$A = \{a_1, a_2,\cdots,a_M \}$
- 時点 $i$ での情報源の出力：$X_i \in A$。確率変数である
- 情報源系列：$X_0 X_1 \cdots X_{n-1}$ で表される情報源記号の系列
- 情報源系列の統計的性質は，$X_0 X_1 \cdots X_{n-1}$ の結合確率分布 $P_{X_0 X_1 \cdots X_{n-1}}(x_0, x_1, \cdots, x_{n-1})$ で表せる
    - $x_0, x_1, \cdots, x_{n-1}$ は任意の $A$ の元である。単に $P(x_0, x_1, \cdots, x_{n-1})$ と書かれることが多い
- 条件付き確率分布 $P_{X_1 | X_0}(x_1 | x_0) = \frac{P_{X_1 X_0}(x_1,~x_0)}{P_{X_0}(x_0)}$：$X_0 = x_0$ であった時の $X_1$ の確率分布。
単に $P(x_1 | x_0)$ と書かれることが多い
:::

### 無記憶定常情報源
各時点の情報源記号の出力が独立同一分布(i.i.d.)に従う情報源。  
この時，任意の $n$ で $P(x_0, x_1, \cdots, x_{n-1}) = \Pi_{i=0}^{n-1} P(x_i)$

### 定常情報源
時間をずらしても統計的性質の変わらない情報源。すなわち，情報源記号の出力は同一の確率分布に従う。（記憶はあっても良い）  
この時，任意の $n,i$ で $P_{X_0 X_1 \cdots X_{n-1}}(x_0, x_1, \cdots, x_{n-1}) = P_{X_i X_{i+1} \cdots X_{i+n-1}}(x_0, x_1, \cdots, x_{n-1})$

### エルゴード情報源
十分長い情報源系列に，その情報源の統計的性質が完全に現れる定常情報源。  
この時，任意の関数 $f: X \to \mathbb{R}$ に対して，  
集合平均：$\overline{f(X)} = \sum_{x\in A}f(x)P_X(x)$，
時間平均 $\braket{f(X)} = \lim_{n \to \infty} \frac{1}{n} \sum_{i=0}^{n-1} f(x_i)$ として，

$\overline{f(X)} = \braket{f(X)}$ となる。

- 例えば，サイコロを振りまくれば 1〜6 が等確率で出ることがわかる。(これは各時点の情報源の出力の確率分布と同じ確率分布)
- 一方で，0だけ or 1 だけとなる情報源は，定常ではあるが，エルゴードではない。(時間をかけても各時点の統計的性質はわからない)
- 長時間での統計的性質は求めやすく，それが情報源の統計的性質と一致するととても嬉しい

### マルコフ情報源
記憶のある情報源の代表例。直前の $m$ 個の出力だけから次の出力の確率分布が決まる情報源 ($m$ 重マルコフ情報源と呼ぶ)。
この時，$P(x_i | x_{i-1},\cdots,x_0) = P(x_i | x_{i-1},\cdots,x_{i-m})$

- $1$ 重マルコフ情報源を単純マルコフ情報源と呼ぶ
- $m$ 重 $q$ 元マルコフ情報源は， $q^m$ 個の状態を持つマルコフモデルで表せる。(それぞれの状態が前 $m$ 個の出力系列と一致)

下記画像は，単純マルコフ情報源のマルコフモデルの例。[第４章 情報源](http://leo.ec.t.kanazawa-u.ac.jp/~nakayama/edu/file/inct_info_theory-2.pdf) より引用
<img src="/img/information/Markov_sources.png "alt="マルコフ情報源" style={{ width: '50%' }} />


**一方で，状態と出力系列が一致していない一般化されたマルコフ情報源は，一般には $m$ 重マルコフ情報源とは異なる。**
- 状態 $s_i$ から次の状態 $s_j$ に遷移する時は出力が $a_k$ である，というように考える場合が多い

### 一般化されたマルコフ情報源
一般化されたマルコフ情報源の状態は，以下の状態集合に分類できる。
- 過渡状態：十分時間が経過すればこの状態に戻ってこない状態 $\to$ 閉じた状態集合から抜け出さない
- 非周期的な閉じた状態集合：任意の時点でこの中の任意の状態を取る状態集合
- 周期的な閉じた状態集合：周期的に，この中の部分集合の任意の状態をとる状態集合

一つの閉じた状態集合のみからなるマルコフ情報源を **既約マルコフ情報源** といい，マルコフ情報源の基本となる。
（そのうち，非周期的なものを正規マルコフ情報源と呼ぶ）

そして実は，正規マルコフ情報源はエルゴード情報源であり，周期的な既約マルコフ情報源も初期状態が条件を満たせばエルゴード情報源となる。

### マルコフ情報源の分析
状態 $\{s_0, s_1,\cdots,s_{N-1}\}$ について，$s_i$ から次に $s_j$ に遷移する，遷移確率を $p_{ij} = P(s_j|s_i)$ と表す。  
この時，遷移確率行列 $\Pi = \begin{pmatrix} p_{0,0} & \cdots & p_{0,N-1}\\ \vdots & \ddots & \vdots \\p_{N-1,0} & \cdots & p_{N-1,N-1}\end{pmatrix}$
を定義する。
- 遷移確率行列は，**各行** の和が $1$。つまり，各行が $s_i$ にいる時の次の状態の確率分布を表す
- $s_i$ から $t$ 時点後に $s_j$ に到達する確率 $p_{ij}^{(t)}$ は，$\Pi^t$ の $(i,j)$ 要素で表される
- 正規マルコフ情報源であるための条件は，任意の $i,j$ で，ある $t_0$ に対し，$p_{ij}^{(t_0)} > 0$ 

さらに，正規マルコフ情報源であれば，$\lim_{t\to \infty}p_{ij}^{(t)} = u_j,~\lim_{t\to \infty}\Pi^t = U$ となる。  
ただし，$\bm{u} = (u_0,\cdots,u_{N-1})$ として，$U = \begin{pmatrix}\bm{u} \\ \vdots \\ \bm{u} \end{pmatrix}$ である。

そこで，時点 $t$ において状態 $s_j$ にいる確率を $w_j^{(t)}$ として，状態分布 $\bm{w_t} = (w_0^{(t)},\cdots,w_{N-1}^{(t)})$ を定義する。
すると，初期分布 $\bm{w_0}$ によらず，極限分布 $\lim_{t\to \infty} \bm{w_t} = \bm{u}$ となる。すなわち，初期状態によらず，定常分布に落ち着く。

:::tip[正規マルコフ情報源のまとめ]
正規マルコフ情報源では，初期状態によらず，十分時間が経過すれば，状態分布 $\bm{w}^{(t)}$ は， $\bm{w}\Pi = \bm{w}$ を満たす **定常分布** $\bm{w}$ に落ち着く。
なお，$\sum_{i=0}^{N-1} w_i = 1$ である。  
また，十分時間経過後は，正規マルコフ情報源は **エルゴード情報源** とみなすことができる。
:::

なお，一般のマルコフ情報源に対しても定常分布は一つ以上存在し，初期分布として定常分布を与えれば，十分時間が経過すれば定常情報源となる。
また，既約情報源であれば，周期的であっても，初期分布として定常分布を与えればエルゴード情報源となる。  
しかし，周期的既約情報源では，初期分布として定常分布以外を与えると，一般には定常情報源にはならない。

---
## 通信路のモデル
通信路は，各時点で一つの情報源記号を受け取り，その情報源記号に対して雑音や歪みを付加し，一つの情報源記号を出力するものとする。
入力アルファベットと出力アルファベットは通常同じであるが，異なる場合もある。
入力アルファベットと出力アルファベットが同じで，その元の数が $r$ である通信路を $r$ 元通信路という。

:::tip[通信路のモデル]
通信路の統計的性質は，任意の入力系列 $X_0 X_1 \cdots X_{n-1}$ に対して，出力系列 $Y_0 Y_1 \cdots Y_{n-1}$ の確率分布   
$P_{Y_0 Y_1 \cdots Y_{n-1} | X_0 X_1 \cdots X_{n-1}}(y_0, y_1, \cdots, y_{n-1} | x_0, x_1, \cdots, x_{n-1})$ 
がわかれば良い。
:::

### 無記憶定常通信路
- **無記憶通信路**：出力が，各時点の入力のみに関係する通信路
- **定常通信路**：時間をずらしても統計的性質が変わらない通信路

すなわちこのとき，$P_{Y|X}(y|x)$ がわかれば良い。

また，入力アルファベット $A = \{a_1, a_2,\cdots,a_r \}$，出力アルファベット $B = \{b_1, b_2,\cdots,b_s \}$ に対して，  
$p_{ij} = P_{Y|X}(b_j|a_i)$ として，通信路の特性を表す **通信路行列** 
$T = \begin{pmatrix} p_{11} & \cdots & p_{1s}\\ \vdots & \ddots & \vdots \\p_{r1} & \cdots & p_{rs}\end{pmatrix}$ を定義できる。
- すなわち，通信路行列が通信路の統計的性質を表す
- **各行** の和が $1$。すなわち，入力が行に，出力が列に対応している (マルコフ情報源の遷移確率行列と同じ)

#### 2 元対称通信路(BSC)：$T = \begin{pmatrix} 1-p & p\\ p & 1-p\end{pmatrix}$ なる通信路
画像は，[第６章 具体的符号化法](http://leo.ec.t.kanazawa-u.ac.jp/~nakayama/edu/file/inct_info_theory-4.pdf)より引用
<img src="/img/information/BSC.png" alt="2元対称通信路" style={{ width: '30%' }} />

#### 2 元対称消失通信路：$T = \begin{pmatrix} 1-p_{\times}-p & p_{\times} & p\\ p & p_{\times} & 1-p_{\times}-p\end{pmatrix}$ なる通信路（確率 $p_{\times}$ で消失してしまう）

- 入力/出力 に対して一様な通信路：入力/出力 からみて，出力/入力 の確率分布が記号を入れ替えれば同じ形になる通信路
    - 対称通信路とも呼ばれる
- 二重に一様な通信路：入力・出力の両方に対して一様な通信路。BSC はこの一つ

### 加法的通信路
：$E$ を通信路の雑音として，出力 $Y = X \oplus E$ というようなモデルを考える。誤り $E$ は各時点に一つずつ発生し，誤り源から発生する誤りの系列を誤り系列と呼ぶ。
- ランダム誤り：誤りが互いに独立で，同一確率分布に従う場合
- バースト誤り：誤りが密集して起こるような場合。
    - ソリッドバースト誤り：連続して誤りが起こる場合。マルコフモデルで表すことが多い
    - ギルバードモデル：誤りが起こりやすい時間帯があるような場合。マルコフモデルにプラスで，状態に応じた確率で誤りが起こると考える。
