---
title: 4. 通信路符号化
---

:::warning[目標]
通信路符号化の方法とその限界を理解する。すなわち，与えられた通信路に対して，どのような入力を行えばより多くの情報を伝達できるかを考える !
:::

## 通信路容量
[通信路のモデル](/docs/information/information-theory/intro#通信路のモデル) も参照。
:::tip[通信路容量]
通信路の入力系列 $\bm{X}_n = X_0 X_1 \cdots X_{n-1}$ ，出力系列 $\bm{Y}_n = Y_0 Y_1 \cdots Y_{n-1}$ と置く。
この時，通信路容量を以下のように定義する。ただし，$\bm{P}(\bm{X}_n)$ は $\bm{X}_n$ の確率分布。
$$
C = \lim_{n\to \infty} \max_{\bm{P}(\bm{X}_n)} \frac{1}{n} I(\bm{X}_n; \bm{Y}_n)
$$

つまり，任意の通信路に対して通信路容量は，入力の確率分布を変化させた時の入力と出力の相互情報量の最大値を示す。
:::
なお **無記憶通信路** であれば，$\displaystyle C = \max_{\bm{P}(\bm{X})} I(X; Y)$ となる。  

また **無記憶通信路** であれば，入力アルファベット $A = \{a_1, a_2,\cdots,a_r \}$，出力アルファベット $B = \{b_1, b_2,\cdots,b_s \}$ に対して，
$p_{ij} = P_{Y|X}(b_j|a_i)$ として，通信路の特性を表す **通信路行列** 
$T = \begin{pmatrix} p_{11} & \cdots & p_{1s}\\ \vdots & \ddots & \vdots \\p_{r1} & \cdots & p_{rs}\end{pmatrix}$ を定義できる。(各行の和が $1$)

- アナログ信号では，帯域幅 $B$ [Hz]，信号の総電力 $S$，ガウスノイズの総電力 $N$ として，単位時間あたりの通信容量 : $C = B\log_2(1 + \frac{S}{N})$ と表される

### 無記憶一様通信路
入力について一様な通信路を考える。
入力からみて，出力の確率分布が記号を入れ替えれば同じ形になる通信路であった。
(すなわち，集合 $\{p_{i1},…,p_{is}\}$ が $i$ によらない)

入力の確率分布を $\bm{p} = (p_1, p_2, \cdots, p_r)$ とすると，  
$H(Y|X) = - \sum_x P(x) \sum_y P(y|x) \log_2 P(y|x) = - \sum_{i=1}^r p_i \sum_{j=1}^s p_{ij} \log_2 p_{ij}$ となる。

ここで，入力について一様なので $H(Y|X) = - \sum_{j=1}^s p_{1j} \log_2 p_{1j}$ となる。( $1$ の部分は何でも良い)

よって，通信路容量 $\displaystyle C = \max_{\bm{p}} H(Y) + \sum_{j=1}^s p_{1j} \log_2 p_{1j}$ となる。

- 例 : 2 元対称通信路 : $T = \begin{pmatrix} 1-p & p\\ p & 1-p\end{pmatrix}$ では，
$C = \max_{p} H(Y) + (1-p) \log_2 (1-p) + p \log_2 p$ となる。$H(Y)$ は入力 $p_1 = p_2 = 0.5$ の時 $1$ を取るので，
$C = 1 + (1-p) \log_2 (1-p) + p \log_2 p = 1 - \mathcal{H}(p)$ となる
    - すなわち，$p = 0,1$ の時は $C = 1$，$p = 0.5$ の時は $C = 0$
- 例 : 2 元対称消失通信路：$T = \begin{pmatrix} 1-p_{\times}-p & p_{\times} & p\\ p & p_{\times} & 1-p_{\times}-p\end{pmatrix}$ では，
$C = \max_{p} H(Y) + (1-p_{\times}-p) \log_2 (1-p_{\times}-p) + p_{\times} \log_2 p_{\times} + p \log_2 p$ となる。
$H(Y)$ は入力 $p_1 = p_2 = 0.5$ の時最大となり，結果として $C = (1 - p_{\times})\left(1 - \mathcal{H}(\frac{p}{1-p_{\times}})\right)$ となる


### 加法的 2 元通信路
$Y = X \oplus E$ というモデルを考える。ただし，$E$ と $X$ は独立とする。  
この時，$I(X; Y) = H(Y) - H(E \oplus X | X) = H(Y) - H(E)$ となる。

ここで，$X$ の確率分布について，$P_X(0) = P_X(1) = 0.5$ とすると，$P_Y(0) = P_Y(1) = 0.5$ となるため，$C = 1 - H(E)$ となる。

なお，これは誤り源に記憶がある場合 (マルコフモデルで表される場合など) でも成り立つ。

---
## 通信路符号化
:::warning[目標]
通信路の雑音や誤りの影響を抑えるために，冗長性を付加して信頼性を向上させる !
:::

:::tip[通信路符号]
通信路の入力アルファベットと出力アルファベットを共に $A = \{a_1, a_2,\cdots,a_r \}$ とする。  
この時，入力系列として $A^n$ から選ばれた $M$ 個の系列の集合 $C$ を **通信路符号** と呼び，それぞれの系列を **符号語** $\bm{w}_i \in C$ と呼ぶ。

また，$A^n$ は **受信空間** とも呼ばれ，受信空間には，入力が $\bm{w}_i$ と推測できる復号領域 $\Omega_i$ と
符号語が推定不可能な領域が広がっている。

<img src="https://siglead.wpx.jp/wp-content/uploads/2022/08/img_chap01_02_sp.png" alt="受信空間のイメージ" style={{ width: '30%' }} />
図は [誤り訂正符号](https://siglead.com/technology/errorcorrectioncode/) より引用
:::
この時，符号語を $M$ 個とした時 $R = \frac{1}{n} \log_2 M$ ビット/記号 を **情報速度** と呼び，この速度で情報を伝達できる。
また，冗長性を加えない場合，$R_{max} = \frac{1}{n}\log_2 r^n$ ビット/記号 とおける ( $r$ 元通信路)。
そこで，$\nu = \frac{R}{R_{max}}$ を **符号化率**，$\rho = 1 - \nu$ を **冗長率** と呼ぶ。(正規化せずに，$R$ を符号化率と呼ぶこともある)

- 通信路符号 $C$ としては等長符号を考えることが多いため，$C \subset A^n$ としている
- 情報速度のイメージは，ありうる符号語のうち何割利用しているか
- **情報速度の最大値 = 通信路容量** である

### 最大事後確率復号 (MAP)
:::warning[目標]
各符号語に対して最適な復号領域の設定方法を考える。つまり，入力 $\bm{w}_i$ を送信し $\bm{y}$ を受信した時，$\bm{w}_i$ と推測できる確率が最大となるようにする。
:::
:::tip[MAP]
入力の確率分布 $P(\bm{w}_i)$ がわかっている場合，$\bm{y}$ を受信した時 $P(\bm{w}_i|\bm{y})$ が最大となる $\bm{w}_i$ と推測し，$\bm{y} \in \Omega_i$ とする。
$$
\hat{\bm{w}} = \arg\max_{\bm{w}_i}P(\bm{w}_i|\bm{y}) = \arg\max_{\bm{w}_i} P(\bm{y}|\bm{w}_i) P(\bm{w}_i)
$$
:::
- 全体の復号誤り確率を最小化するという点で最も最適な復号方式
- ただ，入力の確率分布 $P(\bm{w}_i)$ を知っている or モデル化する必要がある

### 最尤復号法 (Maximum Likelihood Decoding, MLD)
:::tip[最尤復号法]
入力の確率分布が未知の場合，各符号語の入力確率が等しいと仮定すれば，正しく復号される確率 $P_c = \frac{1}{M} \sum_{i=1}^M P(\bm{y} | \bm{w}_i)$ となるので，
各 $\bm{y}$ について，$P(\bm{y}|\bm{w}_i)$ が最大となる $\bm{w}_i$ と推測し，$\bm{y} \in \Omega_i$ とする。

$$
\hat{\bm{w}} = \arg\max_{\bm{w}_i} P(\bm{y}|\bm{w}_i)
$$
:::
- この方法は，入力の確率分布が未知の場合 (特に等確率に近い場合) において有用であるが，
実際に全ての符号語 $\bm{w}_i$ に対して $P(\bm{y}|\bm{w}_i)$ を計算するのは困難である

### 通信路符号化定理
:::tip[通信路符号化定理]
通信路容量 $C$ の通信路に対し，情報速度 $R$ について $R < C$ $\Leftrightarrow$ 
$\forall \epsilon$ に対し，復号誤り率 $P_e < \epsilon$ を満たす情報速度 $R$ の符号が存在する。
:::
証明のイメージ
- $I(\bm{X}_n; \bm{Y}_n) = nC$ となるような無記憶情報源 $S_0$ の長さ $n$ の系列を考え，
代表的系列 $2^{nH(X)}$ のうち $M = 2^{nR}~(R < C)$ 個の系列をランダムに選ぶ。
この時，議論をぶっ飛ばすと受信される代表的系列は平均して $2^{nH(X | Y)}$ 個となる
- よって，復号誤り率 $P_e = 1 - \left(1 - \frac{2^{nR}}{2^{nH(X)}}\right)^{2^{nH(X | Y)}} \approx 2^{-n(C - R)}$ となる

---
## 通信路符号化法
:::warning[目標]
通信路符号化の具体的な方法を学ぶ。すなわち，どのように冗長性を付加して信頼性を向上させるかを考える !
:::
- **誤り検出** : 受信語に誤りが存在することを検出すること。  
- **誤り訂正** : 受信語に誤りが存在することを検出し，正しい符号語に訂正できること。

また，以下のような用語を定義する
- 情報記号 : 情報を伝達するための符号。2 元通信路では情報ビットとも
- 検査記号 : 情報記号の誤り検出のために付加される符号。検査ビットとも
- 誤り検出符号 $\bm{w}$ : 情報記号と検査記号を合わせた，受信側で誤りを検出するための符号。訂正もできるなら，誤り訂正符号とも
- 組織符号 ($(n,k)$ 符号) : $k$ 個の情報記号と $n-k$ 個の検査記号を組み合わせた $n$ 個の符号
    - このとき，効率 $\eta = \frac{k}{n}$ となる
- 線形符号 : 任意の符号語の和もまた符号語となる符号
    - パリティ検査方程式 : 線形符号において，符号語となるための必要十分条件の式
- シンドローム $\bm{s}$ : 検査方程式に受信語を代入した結果。誤りパターンのみによる式となる
    - $\bm{w}$ を送信語として，受信語 $\bm{y} = \bm{w} + \bm{e}$ とした時 $\bm{y}$ のシンドロームは $\bm{e}$ のみに依存する

以下では，$0,1$ からなる長さ $k$ の系列 $x_1 x_2 \cdots x_k$ を 2 元無記憶通信路を介して送信するときを考える。
記憶のある場合は，バースト誤り検出・訂正能力が重要になってくる。
### 単一パリティ検査符号
:::tip[単一パリティ検査符号]
$c = x_1 + x_2 + \cdots + x_k\mod 2$ として，$c$ を系列の末尾に付加した $x_1 x_2 \cdots x_k c$ を送信する。
この時，$1$ 個までの誤り検出が可能である。

なお，$w_1 w_2 \cdots w_n = x_1 x_2 \cdots x_k c$ とした時，任意の符号は $w_1 + \cdots + w_n = 0 \mod 2$ を満たす。
:::
- 情報記号 : $x_1 x_2 \cdots x_k$
- 検査記号 : $c$
- つまり，$(k+1, k)$ 符号で，効率は $\eta = \frac{k}{k+1}$
- パリティ検査方程式 : $w_1 + w_2 + \cdots + w_n = 0 \mod 2$


### 水平垂直パリティ検査符号
:::tip[水平垂直パリティ検査符号]
情報ビットを $k_1\times k_2$ の行列に配置し，行列ごとに単一パリティ検査符号を付加する。結果として，符号長 $(k_1 + 1)(k_2 + 1)$ となる。
この時，$1$ 個までの誤り訂正と，$2$ 個までの誤り検出が可能である。

<img src="https://cdn-ak.f.st-hatena.com/images/fotolife/h/halya_11/20190525/20190525174354.png" alt="水平垂直パリティ検査符号のイメージ" style={{ width: '30%' }} />
画像は [【AP】データの誤りの検出と訂正](https://light11.hatenadiary.com/entry/2019/08/25/233112) より引用
:::
和が偶数とならない行・列を見つけ出し，それぞれ 1 個であれば，その交点のビットを訂正，それ以上であれば 2 個のビットが誤りであると推定できる。


### ハミング符号
:::tip[ハミング符号]
一般には，$(2^m - 1, 2^m - m - 1)$ 符号を考えるが，ここでは $(7,4)$ ハミング符号を考える。
情報ビット $x_1 x_2 x_3 x_4$，検査ビット $c_1 c_2 c_3$ として，$\bm{w} = x_1 x_2 x_3 x_4 c_1 c_2 c_3$ とする。

この時，適切に検査ビットを設定すれば，$1$ 個の誤り訂正が可能である。
:::
$\begin{cases}
c_1 = x_1 + x_2 + x_3\\
c_2 = x_2 + x_3 + x_4\\
c_3 = x_1 + x_2 + x_4
\end{cases}$ として，検査ビットを設定する。この時，パリティ検査方程式は以下のようになる。
$$
\begin{cases}
w_1 + w_2 + w_3 + w_5 = 0 \\
w_2 + w_3 + w_4 + w_6 = 0 \\
w_1 + w_2 + w_4 + w_7 = 0
\end{cases}
$$
ここから，受信語 $\bm{y}$ に対するシンドローム $\bm{s} = (s_1, s_2, s_3)$ を求めると，
$$
\begin{cases}
s_1 = y_1 + y_2 + y_3 + y_5 = e_1 + e_2 + e_3 + e_5 \\
s_2 = y_2 + y_3 + y_4 + y_6 = e_2 + e_3 + e_4 + e_6 \\
s_3 = y_1 + y_2 + y_4 + y_7 = e_1 + e_2 + e_4 + e_7
\end{cases}
$$
となる。この時，シンドロームパターンの $8$ 通りが，それぞれの単一誤り $7$ 通りと誤りなしの $1$ 通りに対応するため，誤り訂正が可能である。

ここで，以下のように生成行列と検査行列を定義すれば簡単に定式化が可能である。
- 生成行列 $G = \begin{pmatrix} 1 & 0 & 0 & 0 & 1 & 0 & 1\\ 0 & 1 & 0 & 0 & 1 & 1 & 1\\ 
0 & 0 & 1 & 0 & 1 & 1 & 0\\ 0 & 0 & 0 & 1 & 0 & 1 & 1\end{pmatrix}$ として，$\bm{w} = \bm{x}G$ となる
- 検査行列 $H = \begin{pmatrix} 1 & 1 & 1 & 0 & 1 & 0 & 0\\ 0 & 1 & 1 & 1 & 0 & 1 & 0\\
1 & 1 & 0 & 1 & 0 & 0 & 1\end{pmatrix}$ として，$\bm{s} = \bm{y}H^T = \bm{e}H^T$ となる ($\bm{y} = \bm{w} + \bm{e}$)
    - この時，$\bm{s}$ が $0$ であれば誤りなし，$\bm{s}$ が $H$ の第 $i$ 列に対応すれば，$i$ 番目のビットが誤りである

---
## 誤り訂正能力
### ハミング距離・ハミング重み
:::tip[ハミング距離・ハミング重み]
二つの $n$ 次元ベクトル $\bm{x} = (x_1, x_2, \cdots, x_n),\bm{y} = (y_1, y_2, \cdots, y_n)$ に対して
- ハミング距離 $d_H(\bm{x}, \bm{y}) = \sum_{i=1}^n \delta(x_i, y_i)$ : 何ビット異なるか
- ハミング重み $w_H(\bm{x}) = d_H(\bm{x}, \bm{0}) = \sum_{i=1}^n \delta(x_i, 0)$ : 何ビット $1$ であるか
:::
- ハミング距離は距離の 3 公理を満たす 
    - $d_H(\bm{x}, \bm{y}) \geq 0, d_H(\bm{x}, \bm{y}) = 0 \Leftrightarrow \bm{x} = \bm{y}, 
    d_H(\bm{x}, \bm{y}) = d_H(\bm{y}, \bm{x}), d_H(\bm{x}, \bm{z}) \leq d_H(\bm{x}, \bm{y}) + d_H(\bm{y}, \bm{z})$

### 限界距離復号法
ここで，符号 $C$ の任意の二つの符号語のハミング距離の最小値を  
$d_{min}(C) = \min_{\bm{w}_i, \bm{w}_j \in C, \bm{w}_i \neq \bm{w}_j} d_H(\bm{w}_i, \bm{w}_j)$ と定義する。

:::tip[限界距離復号法]
$d_{min}(C) = 2t + 1$ であれば，符号 $C$ は $t$ 個までの誤り訂正が可能である。
これは，復号領域 $\Omega_i$ を $\bm{w}_i$ からのハミング距離 $t$ 以下の集合とすれば良いためである。  
また，どの信号領域にも属さない場合は，誤り検出が可能である。つまり，復号領域の半径を $t_1$ とすれば，
$d_{min}(C) - t_1 - 1$ 個までの誤り検出が可能である。
:::
つまり，誤り訂正距離が大きいほど誤り検出距離は小さくなる。

<img src="/img/information/decoding.png" alt="限界距離復号法のイメージ" style={{ width: '50%' }} />
画像は [こちら](https://slidesplayer.net/slide/14286467/) より引用

- $(7,4)$ ハミング符号では，$d_{min}(C) = 3$ なので $1$ 個までの誤り訂正と $2$ 個までの誤り検出が可能
- 水平垂直パリティ検査符号では，$d_{min}(C) = 4$

### 巡回符号
ここで，$n$ 次元ベクトル $\bm{v} = (v_{n-1}, v_{n-2}, \cdots, v_0)$ の   
**多項式表現** $\bm{v}(x) = v_{n-1}x^{n-1} + v_{n-2}x^{n-2} + \cdots + v_0$ を定義する。

:::tip[巡回符号]
最高次 $m$ 次の生成多項式 $G(x)$ を用いて，任意の $n-m$ 次元以下の多項式 $A(x)$ に対し，  
$C = A(x)G(x)$ の多項式で表される符号の集合 $C$ を **巡回符号** と呼ぶ。
:::
- なお，$m$ 次元の多項式の最高次は $x^{m-1}$ であり，$G(x)$ の最高次の係数は $1$ とする
- 巡回符号は線形符号であり，$(n, n-m)$ 符号となる。つまり，検査ビット数は $m$ 個
- 例 : $G(x) = x^4 + x^3 + x^2 + 1$ で情報ビット $3$ の巡回符号は，$A(x) = a_2 x^2 + a_1 x + a_0$ として 
$G(x)A(x)$ で各 $8$ 個の巡回符号を計算できる。ただし，$A(x)$ が情報ビットと対応しているとは限らない

なお，$G(x) | (x^n - 1)$ であれば，$W(x) = \sum_{i=0}^{n-1} w_i x^i$ として，
$w_{n-2} x^{n-1} + \cdots + w_0x + w_{n-1} = xW(x) - w_{n-1} (x^n - 1)$ となり，これも巡回符号となることから，"巡回" と呼ばれる。

### 巡回符号の符号器
画像は [情報理論](https://www-alg.ist.hokudai.ac.jp/~atsu/info_theory/infth2021-14plain.pdf) より引用
<img src="/img/information/cyclic_code_encoder.png" alt="巡回符号の符号器のイメージ" style={{ width: '80%' }} />

情報ビットの多項式表現を $X(x)$ とし，$X(x)x^m = A(x)G(x) + C(x)$ と $A(x),C(x)$ を定義すると，
生成される誤り検出符号は $W(x) = A(x)G(x) = x^m X(x) + C(x)$ となる。

従って，$G(x)$ による割り算回路を作成すれば，$X(x)x^m$ を入力として右から流すことで **レジスタ** から $C(x)$ を得て，$X(x)x^m$ と足すことで，
$X(x)$ の誤り検出符号 $W(x)$ を得ることができる。

下記は，$G(x) = x^4 + x^3 + x^2 + 1$ の割り算回路で，$101$ の巡回符号を生成する例である。$D_3D_2D_1D_0 = 0011$ と $1010000$ を足して，
$1010011$ が生成された誤り検出符号である。
<img src="/img/information/cyclic_code_encoder2.png" alt="巡回符号の符号器の例" style={{ width: '80%' }} />
画像は [情報理論](https://www-alg.ist.hokudai.ac.jp/~atsu/info_theory/infth2021-14plain.pdf) より引用

### 巡回符号の誤り検出
誤り検出だけを行う場合は，受信語 $\bm{y}$ の多項式表現 $Y(x)$ について $\frac{Y(x)}{G(x)}$ の剰余が $0$ であれば，誤りがないと判断できる。
(CRC 方式と呼ばれる)

- 実際の例 : $G(x) = x^{16} + x^{12} + x^5 + 1$ であれば，$d_{min}(C) = 4$ であり，バースト誤り検出能力は $16$ であるらしい