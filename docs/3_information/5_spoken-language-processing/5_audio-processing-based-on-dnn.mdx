---
title: 5. 深層学習に基づく音声処理
---

:::warning[概要]
音声認識では，既存の GMM-HMM 法に代わり，DNN(深層ニューラルネットワーク)を用いた DNN-HMM 法が主流になってきている。
:::
- GMM：混合ガウス分布。音響モデルにおいて，音響特徴ベクトルの確率分布を表現するのに使われている

---
## DNN の基本
NN（ニューラルネットワーク）は，脳の神経細胞（ニューロン）のモデルを元にしたモデル。

### DNN の構造
入力層，隠れ層，出力層から構成される。
#### 入力層：入力データ $\bm{x} = \{x_1, x_2, \ldots, x_n\}$ を受け取る。
#### 隠れ層（中間層）：線形変換 + 非線形変換（正規化演算子）を繰り返す。
- 隠れ層の入力 $\bm{y^{l-1}}$ ，出力 $\bm{y^l}$ とすると，$\bm{y^l} = f(\bm{W^l}\bm{y^{l-1}} + \bm{b^l})$ と表せる
- $f$ は活性化関数で，シグモイド関数，ReLU関数などが使われる
- 隠れ層の次元や層数を自由に変更する
#### 出力層：最終的な出力 $\bm{y} = \{y_1, y_2, \ldots, y_m\}$ を出力する。

扱える問題は多種多様。
- 識別問題：（ノーマライズ）ケプストラム $\rightarrow$ 音素（音素ごとに特定のベクトルを持たせる）
- 音声変換や雑音抑制：回帰問題（音声特徴 $\rightarrow$ 音声特徴）
- 音声合成：回帰問題（テキスト空間 $\rightarrow$ 音響空間）

### 事前学習
入力と出力の関係を学習することで，入力 $\rightarrow$ 出力の特徴を，基底ベクトルを並べたパラメータ $W$ に移していき表現できるようにするイメージ。
実践的には，誤差逆伝播法（バックプロパゲーション）= BP 法が使われる。

例えば，$\bm{\lambda}$ を NN パラメータとして，Kクラス分類をする時，
学習データ $\bm{x_n}$ に対する正解ラベル $\bm{d_n}$ （ワンホットベクトル），出力の事後確率 $P(C_k|\bm{x_n})$ として，
誤差関数（交差エントロピー） $E(\bm{\lambda}) = -\sum_n\sum_k d_n^k \log P(C_k|\bm{x_n};\bm{\lambda})$ を最小化する $\bm{\lambda}$ を求める。
この際，出力層における誤差から順に，隠れ層の誤差の最小化を行っていく。
- ただし，多層の NN にこれを行うと，入力に近い層においてパラメータ更新が実質行われなくなってしまう = **勾配消失問題**

#### 勾配消失問題の解決策
- 活性化関数の選択：シグモイド関数 $\rightarrow$ ReLU関数
- 初期パラメータの設定：Xaviel の初期値，RBM や AE などで事前学習を行うこと
- ResNet(残差ネットワーク)：層を飛び越えるようなスキップ接続により，勾配が深い層に直接伝わる

---
## DNN-HMM 法
:::tip[DNN-HMM 法]
DNN-HMM 法では，音響モデル( + 言語モデル)の HMM における各状態の特徴量出力確率を $P(\bm{o_t}|S_i)$ として，DNN でモデル化する。
- GMM：それぞれの隠れ状態 $S_i$ から，どの音声特徴量 $o_t$ が出力されるかの確率分布 $P(\bm{o_t}|S_i)$ ( = 特徴量分布) を生成モデル化
- DNN：音声特徴量 $\bm{o_t}$ がどの隠れ状態 $S_i$ から出力されたかの確率分布 $P(S_i|\bm{o_t})$ ( = 隠れ状態分布) を識別モデル化
    - $P(\bm{o_t}|S_i) = \frac{P(S_i|\bm{o_t})P(\bm{o_t})}{P(S_i)}$ であり，
        - $P(o_t)$： その特徴ベクトルが全体の音声データでどのくらいの確率で生じるのか
        - $P(S_i)$： $S_i$ の確率分布。学習データの正解ラベルの出現頻度からわかる
:::
- 学習：特徴量 $\bm{o_t}$ を入力として，隠れ状態 $S_i$ を推定するタスクを行う。
そのため，あらかじめ特徴量 $\bm{o_t}$ と対応する隠れ状態 $S_i$ の正解ラベルを用意しておく必要がある（GMM-HMM でビタビアルゴリズムなどを用いて用意する）
    - DNN-HMM では，写像を繰り返すため，MFCC(メル周波数ケプストラム係数)よりも低次な LMFB(メル化対数パワースペクトル)を入力した方が認識精度が高い
    - 入力側の数層は，対象タスクに適した特徴量を抽出する機能を有すると考えられる
    - 特徴量空間が識別に適した空間へと変換される
    - 生成モデルだと，特徴量を追加するには特徴量分布を明示的に導出する必要があったが，識別モデルでは追加特徴量を比較的自由に追加できる
- 音響モデル：単語列が入力された時，それに対応する HMM を作成し，出力された観測確率から音声特徴量を得る。のかな？
- 音響モデル + 言語モデルとして利用：得た音声特徴量からビタビスコアを計算し，最適な状態系列 = 単語列を求める

---
## 様々な NN
### AE（Auto Encoder，自己符号化器）
：入力層，隠れ層，出力層をもち，入力と同じ出力を行う NN
- 隠れ層の次元を小さくすることで，入力データの次元圧縮，特徴抽出を行う
    - 入力 = 出力 となるように，少ない次元に情報を色々持っているはずなので
- AE の隠れ層の出力を特徴量として，他の NN に入力することもある

### RNN（recurrent neural network, 再帰型ニューラルネットワーク）
：1 時刻前の隠れ層の出力を次の隠れ層に入力する NN
<img src="/img/information/rnn.png" width="50%"/>
画像は[RNN：時系列データを扱うRecurrent Neural Networksとは](https://deepage.net/deep_learning/2017/05/23/recurrent-neural-networks.html)より引用
- 未来の隠れ層出力からの影響を考慮すれば **双方向 RNN(BRNN)** となる
- 勾配消失問題と等価な問題が存在する

### LSTM（Long Short-Term Memory）
：RNN の勾配消失問題を回避した NN
<img src="/img/information/lstm.png" width="50%"/>
画像は[LSTM (Long Short-Term Memory)](https://cvml-expertguide.net/terms/dl/rnn/lstm/)より引用
- 入力 $h_{t-1}, x_t$ ，出力 $h_t$ で，4つの素子が存在して1つはメモリセルへの入力，3つは入力ゲート，忘却ゲート，出力ゲートへの入力
- メモリセル $c_t$ は，過去の情報を保持する
- メモリセルへの再帰入力は，忘却ゲートの出力が制御
- メモリセルからの出力を出力ゲートの出力が制御

### CNN（convolutional neural network, 畳み込みニューラルネットワーク）
：画像で頻繁に用いられる，重み行列 $W$ の範囲を絞った NN
<img src="/img/information/cnn.png" width="50%"/>
画像は[CNN (Convolutional Neural Network, 畳み込みニューラルネットワーク)](https://cvml-expertguide.net/terms/dl/cnn/)より引用

第 $l$ 層のニューロンの計算に使う第 $l-1$ 層のニューロンを局所化（限定）した NN で，FIRフィルタとも解釈できる
- $y_j = \sum_{j-\delta \le i \le j + \delta}w_{i-(j-\delta)}x_i$
    - 重みつき和を計算する時に用いる重み行列 $W$ は共有される
    - 共有化される重み行列（局在的行列）を何パターンか用意して，それぞれのパターンで畳み込みを行う

#### 基本構成
- プーリング層：適切な局所的領域を考え，入力のその領域内の最大値や平均値を出力とする層。次元圧縮や位置不変性を持たせる
- 畳み込み層：入力に局所的な重み行列を掛けて線形和を取り活性化関数かけて出力とする層。フィルタを複数用いることで，特徴量を抽出する

#### 音声認識の DNN の入力（音声特徴量）の作成：
時系列情報を含むスペクトル特徴量とその動的特徴 $\rightarrow$ フィルタを複数用意して畳み込み層をその種類分作成する（特徴量抽出） $\rightarrow$ プーリング層で次元圧縮

---
## DNN を利用したモデル
### 言語モデル
:::warning[目標]
過去の単語履歴から次に発声される単語を予測する確率を DNN でモデル化する。  
RNN/LSTM を用いれば理論的には無限長の履歴を考慮可能となるはず。
:::
#### 必要な操作
- 単語のベクトル化：one-hot ベクトルなど。分散表現，埋め込み（embedding）と呼ばれる
    - プロジェクション層：単語の one-hot ベクトル $\bm{w}_t$ を低次元化して $\bm{e}_t = E\bm{w}_t$ に変換する。学習により $E$ が最適化される

### 音声合成
:::warning[目標]
テキスト情報を音声特徴量に変換するモデルを DNN で構築する。
:::
- 音声特徴量ではなく音声波形そのものを生成する方式も検討されている（Wavenet）
#### 比較
- HMM：形態素解析, コンテキスト情報抽出 $\rightarrow$ 音素決定木を HMM の状態系列へ変換して音声特徴量に変換
    - 音素 HMM を繋げて文 HMM を作成している
- DNN：まず，音素継続長を決定して音素に対応する何フレームかをベクトル化。その他の話者情報や前後の音素情報なども含めてベクトル化してあわせる。
そのベクトルを入力，音声特徴量を出力するような回帰型の DNN を構築する

### その他用語など
- ミニバッチ学習：ある程度塊を作って重みの更新をバッチごとに行う
    - epoch：学習データ全体を何回使ったか
- Dropout：過学習を抑えるために学習プロセスにおいて一定のノードを不活性化する。ミニバッチを単位としてランダムに不活性化する
- エンコーダ・デコーダモデル：入力をエンコーダで低次元の中間表現（潜在ベクトル）に圧縮し，それを元にデコーダで出力を行うモデル
    - 中間表現（潜在ベクトル）には重要な情報が集約されている
    - 入力と出力の形が異なる時に適している
    - 例：Seq2Seq モデル（機械翻訳），VAE（変分オートエンコーダ），Transformer（Attention を用いたモデル）