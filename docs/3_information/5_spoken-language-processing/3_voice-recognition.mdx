---
title: 3. 音声認識
---
:::warning[目標]
入力音声を単語列に変換し，文字列として出力する方法を学ぶ！
:::

---
## 音声認識で注意すべき点
1. 多様な発声 $\rightarrow$ 同一文字列 への変換が必要
    - 話者の違いによる音響的変動
    - 音素環境や発声スタイル（感情とか）による音響的変動（**音素**：言語話者が区別する発声の最小単位）
    - 背景雑音や伝送特性など環境による音響的変動
2. 言語的な難しさ
    - 未知語への対応
    - 会話特有の言語的特徴（省略，言い淀み，言い回し，冗長後 etc.）

---
## 音声認識の定式化
ここはめちゃくちゃ重要。

音声の特徴ベクトル $\bm{O} = \{\bm{o}_1, \bm{o}_2, \ldots, \bm{o}_T\}$ が与えられたとき，
単語系列 $W = \{w_1, w_2, \ldots, w_N\}$ が意図されたとされる確率 $P(W|\bm{O})$ を最大化するような単語系列 $W$ を求める問題を考える。
すなわち，$\hat{W} = \arg\max_{W} P(W|\bm{O})$。

また，ベイズの定理より，$P(W|\bm{O}) = \frac{P(\bm{O}|W)P(W)}{P(\bm{O})} = \frac{P(\bm{O}|W)P(W)}{\sum_{W} P(\bm{O}|W)P(W)}$ 
であり，$\sum_{W} P(\bm{O}|W)P(W)$ は $W$ に依存しないので，$\hat{W} = \arg\max_{W} P(\bm{O}|W)P(W)$ が問題となる。

:::tip[音声認識の定式化]
与えられた音声の特徴ベクトル $\bm{O} = \{\bm{o}_1, \bm{o}_2, \ldots, \bm{o}_T\}$，音響モデル $P(\bm{O}|W)$，
言語モデル $P(W)$ として，  
$\hat{W} = \arg\max_{W} P(\bm{O}|W)P(W)$ を求めて，単語系列 $\hat{W} = \{\hat{w}_1, \hat{w}_2, \ldots, \hat{w}_N\}$ を意図した単語列と推定する。
:::
- 音響モデル $P(\bm{o}|w)$：単語 $w$ が特徴量 $\bm{o}$ を持つ確率を表すモデル（ $\bm{O},W$ なら入力と出力が複数）  
話者情報 $s$ にも依存し，  $P(\bm{o}|w) = \sum_sP(\bm{o}|s,w)P(s|w) \approx \sum_sP(\bm{o}|s,w)P(s)$ と近似できる
    - $P(\bm{o}|w)$ は確率変数 $s$ が出てこない**不特定話者音響モデル**
    - $P(\bm{o}|s,w)$ は確率変数 $s$ が出てくる**特定話者音響モデル**：$P(\bm{o}|w)$ を $s$ 用に調整したりする
- 言語モデル $P(W)$：単語列 $W$ がどのくらいの確率で出現するかを表すモデル
    - **事前確率**と呼ばれ，発声前から構築できる

---
## 音響モデル
:::warning[目標]
単語列 $W$ が与えられた時に，音声特徴ベクトル列 $\bm{O}$ が得られる確率 $P(\bm{O}|W)$ をモデル化する！
:::
- 例えば，単語 "people" が与えられたら，音声特徴ベクトルは破裂音の特徴を持つ確率は高いはず
- DTW（動的時間伸縮法）を用いるのも音響モデルの一つ
- 最近は DNN（ディープニューラルネットワーク）一強

### HMM（隠れマルコフモデル）
- マルコフ過程：時刻 $t$ の観測信号 $\bm{o}_t$ がそれまでの有限個の過去信号のみに依存する過程
:::tip[隠れマルコフモデル]
マルコフ過程のうち，観測信号が観測できない状態 $\{S_i\}$ を持つもの。状態を考えることで，**観測信号列（ = 音声特徴ベクトル列）の確率分布をモデル化する。**
- $N$ 個の状態 $\{S_1, S_2, \ldots, S_N\}$ 
- ある時刻で状態 $S_i$ の時，次の時刻で状態 $S_j$ に遷移する確率 $a_{ij} = P(S_j|S_i)$
- それぞれの状態で観測信号 $\bm{o}$ が生成される確率分布 $P(\bm{o}|S_i) = b_i(\bm{o})$
- 初期状態と終了状態の確率分布
:::
- 初期状態や終了状態，状態数 $N$ は事前に決定
- 状態遷移確率 $a_{ij}$ と観測確率 $b_i(\bm{o})$ は訓練データにより学習
    - $b_i(\bm{o})$ の確率分布は，多次元のガウス分布（正規分布）や混合ガウス分布（GMM，正規分布の重ね合わせ）を用いることが多い

:::warning[注意]
各単語（列）や音素ごとに HMM モデルを作成する！

例えば，文 $k$ が $M$ 個の音素で構成されていれば，1 音素あたり 3 状態の HMM モデルを作成し，
それを「結び」つけた $3M$ 状態の文 HMM モデルを作成することが多い。
:::
- 出力である音声特徴ベクトル $\bm{o}$ は，出力元となった状態に対応する各音素の特徴量と対応する
- 学習の時は，連結学習を用いて音素ごとの HMM モデルのパラメータを学習するらしい
- HMM の状態遷移自体が音声認識の結果と捉えられることもある

### HMM を用いた出力計算
単語（列）が $K$ 種類で，それぞれに対応する HMM モデル $M_k$ が作成された時，その全体のモデルを $M = \{M_1, M_2, \ldots, M_K\}$ とする。
この時，$P(\bm{O}|M)$ を求めれば，音響モデル $P(\bm{O}|W)$ を求めたことと同じになる。

:::tip[トレリススコア]
前向き確率 $\alpha_j(t)$：初期状態 $S_1$ から 観測信号列 $\bm{o}_1, \bm{o}_2, \ldots, \bm{o}_t$ を出力して $S_j$ に至る確率
- $\alpha_j(t) = P(\bm{o}_1, \bm{o}_2, \ldots, \bm{o}_t, q_t = S_j | M) = \left(\sum_{i=2}^{N-1} \alpha_i(t-1)a_{ij}\right)b_j(\bm{o}_t)$
    により計算できる
    - $q_t$ は時刻 $t$ での状態
    - $S_1$ は初期状態，$S_N$ は終了状態

これを用いると，$P(\bm{O}|M) = \sum_{i=2}^{N-1} \alpha_i(T)a_{iN}$ ：**トレリススコア**
:::
:::tip[ビタビスコア]
一方で，先の議論で $\sum$ を $\max$ に変えたアルゴリズムも存在する。
- $\phi_j(t) = \left(\max_{i=2}^{N-1} \phi_i(t-1)a_{ij}\right)b_j(\bm{o}_t)$：
時刻 $t$ で観測信号列 $\bm{o}_1, \bm{o}_2, \ldots, \bm{o}_t$ を出力して $S_j$ に至る最大確率

これを用いると，$\hat{P}(\bm{O}|M) = \max_{i=2}^{N-1} \phi_i(T)a_{iN}$ ：**ビタビスコア**：時刻 $T$ 
:::
HMM のパラメータ学習（ $a_{ij}, b_i(\bm{o})$ ）は，トレリススコア，音声認識ではビタビスコアを用いて行うことが多い
- ビタビアルゴリズムは，**動的計画法** と等価なアルゴリズム。イメージは，モデル $M_k$ と出力 $\bm{O}$ から，どのような状態遷移を辿ったかを推定する

### HMM のパラメータ推定
最尤推定法（MLE）：訓練データ $\bm{O}$ が与えられた時，出力確率 $P(\bm{O}|M)$ を最大化するパラメータを求める方法で解くが，状態系列が未知なので直接は解けない。
そこで，EM アルゴリズムを利用した Baum-Welch の反復推定法を用いる。これは局所最適解を得るための手法。

- なんだか難しくて良くわからないが，とりあえず後ろ向き確率を用いるらしい。  
- 参考になりそうな資料：[HMM:隠れマルコフモデル](http://www.iba.t.u-tokyo.ac.jp/~iba/SE/HMM/HMM.pdf)，
[第5章 隠れマルコフモデル （HMM）](http://www.takagi.inf.uec.ac.jp/swr/pdf/studentbook5.pdf)

後ろ向き確率 $\beta_i(t)$：時刻 $t$ で状態 $S_i$ にいる時，観測信号列 $\bm{o}_{t+1}, \bm{o}_{t+2}, \ldots, \bm{o}_T$ を出力して終了状態に至る確率
- $\beta_i(t) = P(\bm{o}_{t+1}, \bm{o}_{t+2}, \ldots, \bm{o}_T | q_t = S_i, M)
 = \sum_{j=2}^{N-1} a_{ij}b_j(\bm{o}_{t+1})\beta_j(t+1)$ により計算できる
- $\beta_i(T) = a_{iN}$ となる
- この時，$P(\bm{O}|M) = \sum_{j=2}^{N-1} a_{1j}b_j(\bm{o}_1)\beta_j(1)$

### 環境依存のモデル
音素環境を考えないものをモノフォンモデル，音素環境を考慮したものをトライフォンモデルと呼ぶ。
トライフォンモデルは，音素の前後に音素環境（すなわち前後の音素による影響）を付け加えたモデル。
ただ，そのままだと $N$ 個の音素に対して $N^3$ 個のモデルが必要になるので，音素決定木を用いた「結び」を使うことが多い。
- 音素決定木は，尤度上昇が最大となるように音素の前後の状況を 2 パターンに分ける（例：前は r か否か）ことを繰り返すイメージ

---
## 言語モデル
:::warning[目標]
単語列 $W$ が出現する確率 $P(W)$ をモデル化する！
言葉で説明すると，音声認識を行う際に言語モデルで可能性のある文章を制約する！
:::
- 音響モデルだけだと，意味不明な文章も作成できるので

### 孤立単語の文字認識
これは言語モデルが不要な場合。それぞれの HMM  = 単語。二つの方法がある。
1. 単語単位で HMM を構築して，入力音声に対して最高スコアを示す単語を認識結果とする
2. 音素単位でモデルを構築して，単語 HMM を音素単位で連結してあり得る単語セットを木構造で表現 = 新たな HMM を作成。
ビタビスコアにより経路を得て，その音素を並べて認識単語とする

### ネットワーク文法（正規文法）
:::tip[ネットワーク文法]
発生されうる文集合をネットワークの形で表現する。ネットワークの経路上（アーク）に単語を並べ，そのネットワークを動くことで文を生成する。
:::
- このネットワークは多くの場合人によって作成される
- 単語を単語 HMM で表現すればネットワーク自体が大きな HMM となり，ビタビ探索で文章を生成できる
    - 全状態を対象にすると計算量が膨大になるので，ビーム探索（時刻 $t$ で高スコアな経路のみを保持）を用いる
- LVCSR（大語彙連続音声認識）では現実的に不可能，文法的にちょっと変な文章は認識不可能

### N-gram モデル（統計的言語モデル）
:::tip[N-gram モデル]
語の局所的な並びに着目し，直前の $N-1$ 語の単語列から次の単語を確率的に予測するモデル。  
言語モデル $P(W) = P(w_1, w_2, \ldots, w_N) = \prod_{i=1}^{N} P(w_i|w_{i-1}, w_{i-2}, \ldots, w_{i-N+1})$
:::
- $N=1$：ユニグラムモデル（文脈非依存），$N=2$：バイグラムモデル，$N=3$：トライグラムモデル
- 全く同じ文でなくても，同じ意味を持つ文に対して高い確率を与える：確率値の平滑化
    - 類義語を一つのクラスとするクラス言語モデルもある

### 言語モデルの評価指標
#### 単語パープレキシティ（PP）：単語分岐数（候補単語数）。なるべく小さい方が良い。
- データ $w_1,…w_K$ に対して，
$PP = P(\omega_1,\dots \omega_K)^{-\frac{1}{K}} = \left(\prod_{n=1}^K \frac{1}{P(w_n|w_{n-2}^{n-1})}\right)^\frac{1}{K}$  
- エントロピー化：$\log_2 PP = -\frac{1}{K}\sum_{n=1}^K \log_2 P(w_n|w_{n-2}^{n-1})$
- 語彙サイズ $N$ で等確率の場合，$PP = N$ となる
- 未知語は，UNK という単語として扱うことが多い $\rightarrow$ 未知語ばかりでも PP が小さくなるので，APP（補正単語パープレキシティ）を用いることもある
    - 未知語種類数 $m$，未知語出現数 $o$ として，$\log_2 APP = -\frac{1}{K}\left(\sum_{n=1}^K \log_2 P(w_n|w_{n-2}^{n-1}) - o\log_2 m\right)$

### 仮説探索（デコーディング）
：音響モデルと言語モデルを組み合わせて，最適な単語列を探索すること。単純に尤度を足し合わせる他にもいろんな方法がある。
- 言語モデル尤度に重み(>1)をかけて足し合わせたものをスコアとする方がいいらしい

#### N-gram モデルをネットワーク文法として解釈する
**重要。** N-gram モデルを HMM に組み込む。以下はバイグラムの場合。
1. 全単語分の状態を持つ HMM （音素 HMM を並べた HMM）をネットワークとして並べる
2. 各単語から次の単語に遷移する際に N-gram モデルの確率分布を適応（全単語と全単語が確率遷移で繋がるイメージ）
3. **得た音声特徴ベクトル列に対してビタビスコアを計算して，最適な単語列を得る**
    - 音声と仮説の照合（ = 尤度計算）と枝刈り（ビーム探索や N-best ）をひたすら繰り返す必要がある

#### 2-pass decoding：単純なモデルで先に認識処理を行い，（前段の途中結果などを用いつつ）後段で詳細なモデルを用いる
- 例えば，モノグラム $\rightarrow$ もっと詳細なモデル
- そうすれば，例えば後段のビーム探索で，前段の結果（ = 未来の情報）を使うことができる

#### 挿入ペナルティ：単語遷移ごとに一定のペナルティを対数累積尤度に加える
- 短い単語が並び過ぎるのを防ぐ

#### WFST（重み付き有限状態トランスデューサ）：有限オートマトンの一種
音声認識のモデルは WFST で表現できるらしい。コンピュータの処理能力が上がったために仮説探索空間を全て展開できるようになったため注目された。
参考になりそうな記事：[重み付き有限状態トランスデューサによる音声認識](https://www.gavo.t.u-tokyo.ac.jp/~mine/japanese/nlp+slp/IPSJ-MGN451005.pdf)